{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Synonyms from WordNet\n",
    "\n",
    "If you remember we installed NLTK packages using nltk.download(). One of the packages was WordNet.\n",
    "\n",
    "*WordNet is a database which is built for natural language processing. It includes groups of synonyms and a brief definition.*\n",
    "\n",
    "You can get these definitions and examples for a given word like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Synset('corrode.v.01')\n",
      "cause to deteriorate due to the action of water, air, or an acid\n",
      "['The acid corroded the metal', 'The steady dripping of water rusted the metal stopper in the sink']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "syn = wordnet.synsets(\"eat\")\n",
    "\n",
    "print(len(syn))\n",
    "\n",
    "print(syn[5])\n",
    "\n",
    "print(syn[5].definition())\n",
    " \n",
    "print(syn[5].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet includes a lot of definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the branch of information science that deals with natural language information\n",
      "a soothsaying spirit or a person who is possessed by such a spirit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "syn = wordnet.synsets(\"NLP\")\n",
    " \n",
    "print(syn[0].definition())\n",
    " \n",
    "syn = wordnet.synsets(\"Python\")\n",
    " \n",
    "print(syn[1].definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use WordNet to get synonymous words like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system', 'calculator', 'reckoner', 'figurer', 'estimator', 'computer']\n",
      "['calculator', 'computing_device', 'computing_machine', 'reckoner', 'computer', 'data_processor', 'electronic_computer', 'information_processing_system', 'figurer', 'estimator']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "synonyms = []\n",
    "\n",
    "for syn in wordnet.synsets('Computer'):\n",
    "    print(len(syn.lemmas()))\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.append(lemma.name())\n",
    " \n",
    "print(synonyms)\n",
    "print(list(set(synonyms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Antonyms from WordNet\n",
    "You can get the antonyms words the same way, all you have to do is to check the lemmas before adding them to the array if it’s an antonym or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('pain.n.01.pain') []\n",
      "Lemma('pain.n.01.hurting') []\n",
      "Lemma('pain.n.02.pain') [Lemma('pleasure.n.01.pleasure')]\n",
      "Lemma('pain.n.02.painfulness') []\n",
      "Lemma('pain.n.03.pain') []\n",
      "Lemma('pain.n.03.pain_sensation') []\n",
      "Lemma('pain.n.03.painful_sensation') []\n",
      "Lemma('pain.n.04.pain') []\n",
      "Lemma('pain.n.04.pain_in_the_neck') []\n",
      "Lemma('pain.n.04.nuisance') []\n",
      "Lemma('annoyance.n.04.annoyance') []\n",
      "Lemma('annoyance.n.04.bother') []\n",
      "Lemma('annoyance.n.04.botheration') []\n",
      "Lemma('annoyance.n.04.pain') []\n",
      "Lemma('annoyance.n.04.infliction') []\n",
      "Lemma('annoyance.n.04.pain_in_the_neck') []\n",
      "Lemma('annoyance.n.04.pain_in_the_ass') []\n",
      "Lemma('trouble.v.05.trouble') []\n",
      "Lemma('trouble.v.05.ail') []\n",
      "Lemma('trouble.v.05.pain') []\n",
      "Lemma('pain.v.02.pain') []\n",
      "Lemma('pain.v.02.anguish') []\n",
      "Lemma('pain.v.02.hurt') []\n",
      "['pleasure']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    " \n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"pain\"):\n",
    "#     print(\"====\", syn.definition())\n",
    "#     print(\"+++++\", syn)\n",
    "#     print(len(syn.lemmas()))\n",
    "#     print(syn.lemmas())\n",
    "    for l in syn.lemmas():\n",
    "        print(l, l.antonyms())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    " \n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Word Stemming\n",
    "\n",
    "Word stemming means removing affixes from words and return the root word. Ex: The stem of the word working => work.\n",
    "\n",
    "Search engines use this technique when indexing pages, so many people write different versions for the same word and all of them are stemmed to the root word.\n",
    "\n",
    "There are many algorithms for stemming, but the most used algorithm is Porter stemming algorithm.\n",
    "\n",
    "NLTK has a class called PorterStemmer which uses Porter stemming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    " \n",
    " \n",
    "print(PorterStemmer().stem('working'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming non-English Words\n",
    "\n",
    "SnowballStemmer can stem 13 languages besides the English language.\n",
    "\n",
    "The supported languages are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    " \n",
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing Words Using WordNet\n",
    "\n",
    "Word lemmatizing is similar to stemming, but the difference is the result of lemmatizing is a real word.\n",
    "\n",
    "Unlike lemmatizing, when you try to stem some words, it will result in something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "print(stemmer.stem('increases'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we try to lemmatize the same word using NLTK WordNet, the result is correct:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(lemmatizer.lemmatize('increases'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sometimes, if you try to lemmatize a word like the word playing, it will end up with the same word.\n",
    "\n",
    "This is because the default part of speech is nouns. To get verbs, you should specify it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(lemmatizer.lemmatize('acting', pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "acting\n",
      "acting\n",
      "acting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(lemmatizer.lemmatize('acting', pos=\"v\"))\n",
    " \n",
    "print(lemmatizer.lemmatize('acting', pos=\"n\"))\n",
    " \n",
    "print(lemmatizer.lemmatize('acting', pos=\"a\"))\n",
    " \n",
    "print(lemmatizer.lemmatize('acting', pos=\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization Difference\n",
    "OK, let’s try stemming and lemmatization for some words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stone\n",
      "speak\n",
      "bedroom\n",
      "joke\n",
      "lisa\n",
      "purpl\n",
      "----------------------\n",
      "stone\n",
      "speaking\n",
      "bedroom\n",
      "joke\n",
      "lisa\n",
      "purple\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "from nltk.stem import PorterStemmer\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(stemmer.stem('stones'))\n",
    " \n",
    "print(stemmer.stem('speaking'))\n",
    " \n",
    "print(stemmer.stem('bedroom'))\n",
    " \n",
    "print(stemmer.stem('jokes'))\n",
    " \n",
    "print(stemmer.stem('lisa'))\n",
    " \n",
    "print(stemmer.stem('purple'))\n",
    " \n",
    "print('----------------------')\n",
    " \n",
    "print(lemmatizer.lemmatize('stones'))\n",
    " \n",
    "print(lemmatizer.lemmatize('speaking'))\n",
    " \n",
    "print(lemmatizer.lemmatize('bedroom'))\n",
    " \n",
    "print(lemmatizer.lemmatize('jokes'))\n",
    " \n",
    "print(lemmatizer.lemmatize('lisa'))\n",
    " \n",
    "print(lemmatizer.lemmatize('purple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
